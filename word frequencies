import pandas as pd
df['brand'] = df['brand'].str.strip()
print(df['brand'].unique())

#tokenizing words
df.columns = df.columns.str.strip()
df['cw items'] = df['cw items'].fillna('')
def tokenize(text):
    words = re.findall(r'\b\w+\b', text.lower())
    return [word for word in words if word != 'non']
df['tokens'] = df['cw items'].apply(tokenize)
#counting highest word count for the whole column, with each word being a token

#function to count word frequency
def count_words(df):
    all_tokens = [token for tokens_list in df['tokens'] for token in tokens_list]
    return Counter(all_tokens)
word_counts = count_words(df)

word_counts_df = pd.DataFrame(word_counts.items(), columns=['word', 'count'])
def plot_top_words(top_n=10):
    top_words = word_counts_df.nlargest(top_n, 'count')

    plt.figure(figsize=(1, 100))
    sns.barplot(data=top_words, x='count', y='word', palette='Set3')
    plt.title(f'Top {top_n} Words for Entire Column')
    plt.xlabel('Count')
    plt.ylabel('Word')
    plt.savefig('words count.png') 
    plt.show()
plot_top_words()

#counting whole description of each item as one token
def tokenize(text, delimiter='+'):

    tokens = text.split(delimiter)
    tokens = [token.strip().lower() for token in tokens]
    return tokens
all_tokens = []

for answer in df['cw items']:
    all_tokens.extend(tokenize(answer))

#Removing unwanted tokens
tokens_to_exclude = {'non'}
filtered_tokens = [token for token in all_tokens if token not in tokens_to_exclude]

token_counts = Counter(filtered_tokens)

freq_df = pd.DataFrame(token_counts.items(), columns=['Token', 'Frequency'])
top_freq_df = freq_df.sort_values(by='Frequency', ascending=False).head(10)

plt.figure(figsize=(14, 6))
sns.barplot(data=top_freq_df, x='Frequency', y='Token', palette='pastel')
plt.title('Expression Frequencies')
plt.xlabel('Frequency')
plt.ylabel('items')
plt.savefig('expression frequencies.png')
plt.show()
